{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for Codon Usage Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Classification Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingRegressor\n",
    "\n",
    "# Metric tools, and utility methods\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report,accuracy_score,recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UUC      UUA      UUG      CUU      CUC      CUA      CUG      AUU  \\\n",
      "0  0.01203  0.00050  0.00351  0.01203  0.03208  0.00100  0.04010  0.00551   \n",
      "1  0.01357  0.00068  0.00678  0.00407  0.02849  0.00204  0.04410  0.01153   \n",
      "2  0.02180  0.01357  0.01543  0.00782  0.01111  0.01028  0.01193  0.02283   \n",
      "3  0.02245  0.01619  0.00992  0.01567  0.01358  0.00940  0.01723  0.02402   \n",
      "4  0.01371  0.00767  0.03679  0.01380  0.00548  0.00473  0.02076  0.02716   \n",
      "\n",
      "       AUC      AUA  ...      AGA      AGG      GAU      GAC      GAA  \\\n",
      "0  0.02005  0.00752  ...  0.01303  0.03559  0.01003  0.04612  0.01203   \n",
      "1  0.02510  0.00882  ...  0.01696  0.03596  0.01221  0.04545  0.01560   \n",
      "2  0.01604  0.01316  ...  0.01974  0.02489  0.03126  0.02036  0.02242   \n",
      "3  0.02245  0.02507  ...  0.01410  0.01671  0.03760  0.01932  0.03029   \n",
      "4  0.00867  0.01310  ...  0.01494  0.01734  0.04148  0.02483  0.03359   \n",
      "\n",
      "       GAG      UAA      UAG      UGA  Kingdom_Code  \n",
      "0  0.04361  0.00251  0.00050  0.00000             9  \n",
      "1  0.04410  0.00271  0.00068  0.00000             9  \n",
      "2  0.02468  0.00391  0.00000  0.00144             9  \n",
      "3  0.03446  0.00261  0.00157  0.00000             9  \n",
      "4  0.03679  0.00000  0.00044  0.00131             9  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192071/964674226.py:1: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../raw_data/codon_usage.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../raw_data/codon_usage.csv')\n",
    "\n",
    "df['Kingdom'] = df['Kingdom'].astype('category')\n",
    "df['Kingdom_Code'] = df['Kingdom'].cat.codes\n",
    "\n",
    "codon_df = df.loc[:,df.columns[6:]]\n",
    "\n",
    "# There is a string data on position 5063, so we need to drop it:\n",
    "codon_df = codon_df.drop([5063])\n",
    "codon_df = codon_df.apply(pd.to_numeric)\n",
    "print(codon_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Kingdom Category Based on Codon Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = codon_df.iloc[:,:-1]\n",
    "y = codon_df['Kingdom_Code']\n",
    "\n",
    "## Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,   3,   0,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  3, 564,   1,   0,   4,   0,   7,   0,   0,   5,   0],\n",
       "       [  0,  12, 203,   0,   2,   0,  30,   0,   0,   9,  13],\n",
       "       [  0,   0,   0, 101,   0,   0,   0,   4,   3,   0,   6],\n",
       "       [  1,   8,   0,   0,  32,   0,   0,   0,   0,   3,   0],\n",
       "       [  0,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   7,  12,   0,   1,   0, 479,   0,   0,   5,   1],\n",
       "       [  0,   0,   0,  13,   0,   0,   0,  21,   2,   0,   0],\n",
       "       [  0,   0,   0,  19,   0,   0,   0,   0,  24,   0,   0],\n",
       "       [  0,  10,   4,   0,   0,   0,  21,   0,   0, 532,   0],\n",
       "       [  0,   1,   5,   7,   0,   0,   1,   0,   2,   5, 394]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        25\n",
      "           1       0.93      0.97      0.95       584\n",
      "           2       0.90      0.75      0.82       269\n",
      "           3       0.72      0.89      0.80       114\n",
      "           4       0.82      0.73      0.77        44\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.89      0.95      0.92       505\n",
      "           7       0.84      0.58      0.69        36\n",
      "           8       0.77      0.56      0.65        43\n",
      "           9       0.95      0.94      0.94       567\n",
      "          10       0.95      0.95      0.95       415\n",
      "\n",
      "    accuracy                           0.91      2606\n",
      "   macro avg       0.78      0.74      0.76      2606\n",
      "weighted avg       0.91      0.91      0.91      2606\n",
      "\n",
      "0.9098234842670759\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "display(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m total_test_case \u001b[39m=\u001b[39m test_df\u001b[39m.\u001b[39mCheck\u001b[39m.\u001b[39mcount()\n\u001b[1;32m     10\u001b[0m correct_test_predict \u001b[39m=\u001b[39m test_df\u001b[39m.\u001b[39mvalue_counts(\u001b[39m'\u001b[39m\u001b[39mCheck\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m incorrect_test_predict \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mvalue_counts(\u001b[39m'\u001b[39m\u001b[39mCheck\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of All Test Cases: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(total_test_case))\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of Correct Prediction: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(correct_test_predict))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "test_df = pd.DataFrame([y_test.tolist(), y_pred.tolist()])\n",
    "test_df = test_df.transpose()\n",
    "\n",
    "test_df = test_df.rename(columns = { 0: \"y_test\", 1: \"y_predict\"})\n",
    "test_df['Check'] = np.where(test_df['y_test'] == test_df['y_predict'], 1, 0)\n",
    "\n",
    "\n",
    "total_test_case = test_df.Check.count()\n",
    "correct_test_predict = test_df.value_counts('Check')[1]\n",
    "incorrect_test_predict = test_df.value_counts('Check')[0]\n",
    "\n",
    "print(\"Number of All Test Cases: {}\".format(total_test_case))\n",
    "\n",
    "print(\"Number of Correct Prediction: {}\".format(correct_test_predict))\n",
    "\n",
    "print(\"Number of Incorrect Prediction: {}\".format(incorrect_test_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
